import pandas as pd
import json
import ast
import argparse

parser = argparse.ArgumentParser(allow_abbrev=False, description="Json parser program !", epilog='Enjoy the parsing json! :)')
parser.add_argument('--jsonInputPath', action='store', type=str , default="sample.json", help="your json input file !")
parser.add_argument('--csvOutPutPath', action='store', type=str,  default="sample_out.csv", help="your parsed csv file !")
parser.add_argument('--metadataCsvFile', action='store', type=str, default="metadata.csv", help="your metadata csv file !")
parser.add_argument('--lookupCsvFile', action='store', type=str, default="lookup.csv", help="your lookup csv file !")


def read_json_as_dict(json_file):
    with open(json_file, 'r') as reader:
        return json.loads(ast.literal_eval(reader.read())['response'])


# without response
def read_json_as_dict_2(json_file):
    with open(json_file, 'r') as reader:
        return json.loads(reader.read())


def get_csv_df(csv_file):
    return pd.read_csv(csv_file, index_col=0)


def get_decoded_or_lookup_value(df,encoded_column, value, decode_column):
    result=df.query('{} == "{}"'.format(encoded_column, value))
    if result.empty:
        return encoded_column
    else:
        return result.get(decode_column).values[0]


def isfloat(value):
  try:
    float(value)
    return True
  except ValueError:
    return False


def value_to_padded_double_including_digit(s, padding):
    # get decimal and integer padding
    padding_s = padding.split(".")
    if len(padding_s) == 1:
        padding_s.append("2")
    #s_s = s.split(".")
    sum = int(padding_s[0])+int(padding_s[1])+1
    format_s = '{:0'+str(sum)+'.'+padding_s[1]+'f}'
    f = format_s.format(float(s))
    return f


def value_to_padded_double_including_digit_exclude_sign(s, padding):
    # get decimal and integer padding
    padding_s = padding.split(".")
    if len(padding_s) == 1:
        padding_s.append("2")
    #s_s = s.split(".")
    sum = int(padding_s[0])+int(padding_s[1])+1
    if '-' in s:
        sum=sum+1
    format_s = '{:0'+str(sum)+'.'+padding_s[1]+'f}'
    f = format_s.format(float(s))
    return f


def value_to_padded_double(s, padding):
    # get decimal and integer padding
    padding_s = padding.split(".")
    if len(padding_s) == 1:
        padding_s.append("2")
    s_s = s.split(".")
    sum = int(padding_s[0])+len(s_s[0])+int(padding_s[1])+1
    format_s = '{:0'+str(sum)+'.'+padding_s[1]+'f}'
    f = format_s.format(float(s))
    return f


def value_to_padded_integer(value, padding):
    value_i = str(int(float(value))) if isfloat(value) else value
    return value_i.zfill(int(padding) + len(value_i))


def value_to_padded_integer_including_digit(value, padding):
    value_i = str(int(float(value))) if isfloat(value) else value
    return value_i.zfill(int(padding))


def value_to_padded_integer_including_digit_exclude_sign(value, padding):
    value_i = str(int(float(value))) if isfloat(value) else value
    if '-' in value_i:
        padding=padding+1
    return value_i.zfill(int(padding))


def parse_json_as_csv(json_dict: dict, csv_out:str, metadata_csv:str,lookup_csv:str):

    export_obj = []
    export_val = {}
    df_metadata = get_csv_df(metadata_csv)
    df_lookup = get_csv_df(lookup_csv)
    template_values = df_metadata['N'].tolist()

    for x in json_dict["pipelineResults"]:
        for y in x['pipelineResult']:
            attributes = y["c"]["a"]
            person_id = y["c"]["p"]
            export_val["MEMBER_ID"] = get_decoded_or_lookup_value(df_lookup, "P", person_id, "m")
            # first write which is there in metadata then write rest
            for attr in attributes:
                value_f=''
                value:str = attr["value"]
                # get padding for value id
                padding = get_decoded_or_lookup_value(df_metadata,"N",attr["id"], "Padding")
                casting = get_decoded_or_lookup_value(df_metadata,"N",attr["id"], "casting")
                if casting == 'Double':
                    value_f = value_to_padded_double_including_digit(value, str(padding))
                elif casting == 'Integer':
                    value_f =value_to_padded_integer_including_digit(value,padding)
                else:
                    value_f = value
                attr["value"] = value_f
                export_val[attr["id"]] = value_f
            export_obj.append(export_val)

    df_csv = pd.DataFrame.from_dict(rearrange_dict(export_obj,template_values))
    df_csv.to_csv(csv_out, index=False, header=True)


def rearrange_dict(dict_SL:list, m_list:list):
   dumped_object = []
   for dict_S in dict_SL:
     n_export_obj = {}
     for l in m_list:
        d_export_obj = {}
        for key in dict_S:
            if l == key or key == "M":
                n_export_obj[key] = dict_S[key]
            else:
                d_export_obj[key]=dict_S[key]
     n_export_obj.update(d_export_obj)
     dumped_object.append(n_export_obj)
   return  dumped_object


if __name__ == '__main__':
    args = parser.parse_args()
    print("executing scripts with inputs as below...")
    print("input JSON => {}\nparsed CSV => {}\nmetadata CSV => {}\nlookup CSV => {}".format(args.jsonInputPath,
                                                                                            args.csvOutPutPath,
                                                                                            args.metadataCsvFile,
                                                                                            args.lookupCsvFile))

    parse_json_as_csv(read_json_as_dict(args.jsonInputPath),args.csvOutPutPath,args.metadataCsvFile,args.lookupCsvFile)

# Else the module was imported and it has a __file__ attribute that will be the full path of the module.
else:
    print("not a script !")
